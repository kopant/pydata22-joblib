{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ccd656c-35ed-4e44-8e53-8d60b9f65c7c",
   "metadata": {},
   "source": [
    "# In this notebook we will demonstrate the use of the joblib package to parallelize a machine learning workflow for text data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82eacb8-3425-475c-9d95-9136e7ef3772",
   "metadata": {},
   "source": [
    "## Amazon Fine Food Reviews data has been downloaded from [Kaggle](https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6761a96b-94bd-44c0-8807-57f0eebc3496",
   "metadata": {},
   "source": [
    "### The data consists of ~500,000 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7538849d-cad5-4c5c-95ef-5f2fa883a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9535112c-f6e1-4a61-b6ab-624b8c261037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 500)\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.width', 1000)\n",
    "pd.set_option('max_colwidth', 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "432c2d9a-008f-4d60-9d9b-fa3f73618f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.13 s, sys: 354 ms, total: 3.48 s\n",
      "Wall time: 3.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"/home/ciel/Documents/data/Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4db43790-b4d8-4a0d-9782-58ee5f9702b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "865b515f-6c12-4838-aa14-f862dd511de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
       "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ab5ae92-dc71-44b1-98d8-082a8ce79a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The flavor is very medicinal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary  \\\n",
       "0  Good Quality Dog Food   \n",
       "1      Not as Advertised   \n",
       "2  \"Delight\" says it all   \n",
       "3         Cough Medicine   \n",
       "4            Great taffy   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Text  \n",
       "0                                                                                                                                                                                                                                                        I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.  \n",
       "1                                                                                                                                                                                                                                                                                                                                 Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".  \n",
       "2  This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch.  \n",
       "3                                                                                                                                                                                                                                                                                                    If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The flavor is very medicinal.  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                   Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dca7e0a-02d9-49a8-a791-9a7e2da7c22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                                                                                                                                                               I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.\n",
       "1                                                                                                                                                                                                                                                                                                                                        Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".\n",
       "2         This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch.\n",
       "3                                                                                                                                                                                                                                                                                                           If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The flavor is very medicinal.\n",
       "4                                                                                                                                                                                                                                                                                                                                                                                          Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.\n",
       "                                                                                                                                                                                                                                                                      ...                                                                                                                                                                                                                                                              \n",
       "568449                                                                                                                                                                                                                                                                                                                                                                            Great for sesame chicken..this is a good if not better than resturants I have eaten at..My husband loved it..will find other recipes to use this in..\n",
       "568450                                                                                                                                                                                                                                                                     I'm disappointed with the flavor. The chocolate notes are especially weak. Milk thickens it but the flavor still disappoints. This was worth a try but I'll never buy again. I will use what's left, which will be gone in no time thanks to the small cans.\n",
       "568451                                                                                                                                             These stars are small, so you can give 10-15 of those in one training session.  I tried to train our dog with \"Ceaser dog treats\",  it just made our puppy hyper.  If you compare the ingredients, you will know why.  Little stars has just basic food ingredients without any preservatives and food coloring.  Sweet potato flavor also did not make my hand smell like dog food.\n",
       "568452                                                                                                                                                                                                                                                                                                                         These are the BEST treats for training and rewarding your dog for being good while grooming.  Lower in calories and loved by all the doggies.  Sweet potatoes seem to be their favorite Wet Noses treat!\n",
       "568453                                                                                                                                                                                                                                                                                                                                                                                                                  I am very satisfied ,product is as advertised, I use it on cereal, with raw vinegar, and as a general sweetner.\n",
       "Name: Text, Length: 568454, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd4f1dc6-2eb1-448e-ba32-a2131950a475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     52268\n",
       "2     29769\n",
       "3     42640\n",
       "4     80655\n",
       "5    363122\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Score.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28baf512-2e68-4c5c-a7c7-85ae1654d673",
   "metadata": {},
   "source": [
    "### Lengths of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bfc28bc-9c9d-48fe-b5a0-b9d21858f71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10      127.0\n",
       "0.20      161.0\n",
       "0.30      199.0\n",
       "0.40      246.0\n",
       "0.50      302.0\n",
       "0.60      371.0\n",
       "0.70      465.0\n",
       "0.80      606.0\n",
       "0.90      877.0\n",
       "0.99     2166.0\n",
       "1.00    21409.0\n",
       "Name: Text, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_lens = df.Text.apply(len).quantile([i * 0.1 for i in range(1, 10)] + [0.99, 1.0])\n",
    "text_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e5b5ed-5263-4458-8ab7-b72e9a603e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a750bd8-1669-4fce-af81-945c0b691d0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ML Workflow Examples: identifying opportunities for parallelization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ad4b2c-12c7-4549-9cef-521e59978c69",
   "metadata": {},
   "source": [
    "# Expensive pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1775eb8d-63a2-4a80-873c-7d4d799ad6b2",
   "metadata": {},
   "source": [
    "#### Remove text regarding shipping experience from review text, to focus solely on customer's review of product details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e5509af4-4422-4293-bd1f-f444172c3cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"Liked it. The package arrived fast! The cookies were flaky and tender. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0eec4b6a-e2dd-4273-a6d9-2bf8d9da5b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = \\\n",
    "re.split(\"([.!?]+)\", test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0a64b7a0-112e-41b5-949a-e44f5922d19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Liked it',\n",
       " '.',\n",
       " ' The package arrived fast',\n",
       " '!',\n",
       " ' The cookies were flaky and tender',\n",
       " '.',\n",
       " ' ']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "122e45fc-4bd9-49d4-9d66-bdbe80c79e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [\"\".join(result[i:i+2]) for i in range(0, len(result), 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4818ed4b-bfa9-4236-a1ca-b93d58244a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Liked it.',\n",
       " ' The package arrived fast!',\n",
       " ' The cookies were flaky and tender.',\n",
       " ' ']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1eb47af4-85aa-400e-a2d5-f38878375cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "shipping_pattern = \\\n",
    "\"[^!?.]*((shipping|delivery)|\\\n",
    "((arrived|came|delivered)[a-z\\s]*(slow|fast|quick)))[^!?.]*[!?.]*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f7aba5b4-7244-490f-8baf-28afc66af230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Liked it. The cookies were flaky and tender. '"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join([re.sub(shipping_pattern, \"\", s) for s in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "66658501-d729-4349-b26a-fc856421b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_clean(text, removal_pattern):\n",
    "    \"\"\"\n",
    "    Regex pattern flags sentences for removal from text.\n",
    "    \n",
    "    # Arguments\n",
    "        text: string\n",
    "        removal_pattern: regex pattern string\n",
    "        \n",
    "    # Returns\n",
    "        string of cleaned text\n",
    "    \"\"\"\n",
    "    # First split text into sentences\n",
    "    sentences = re.split(\"([.!?]+)\", text)\n",
    "    sentences = [\"\".join(sentences[i:i+2]) \n",
    "                 for i in range(0, len(sentences), 2)]\n",
    "    # Filter each sentence\n",
    "    cleaned = \"\".join([re.sub(removal_pattern, \"\", s) \n",
    "                       for s in sentences])\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1ad2270d-95a3-4499-b977-b34074fcccaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Liked it. The cookies were flaky and tender. '"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex_clean(test_text, shipping_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00966c2-45d2-4007-8cdc-ee88cfe2e858",
   "metadata": {},
   "source": [
    "## Without joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2eddbc-b14e-48f7-b69f-66e52be0bc9d",
   "metadata": {},
   "source": [
    "#### Time the job to see how it scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5ddfe011-afee-447e-a05b-395ab8953c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 20s, sys: 1.41 s, total: 13min 22s\n",
      "Wall time: 13min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cleaned_text = df.Text.apply(regex_clean, removal_pattern=shipping_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e310c97-ab14-4d77-985f-550df76bba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1000 records: Wall time: 1.24 s\n",
    "# 10000 records: Wall time: 12.9 s\n",
    "# 100000 records: Wall time: 2min 18s\n",
    "# 568454 records: Wall time: 13min 27s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eab812db-149d-4cee-ae01-4813fa3d8455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 57s, sys: 1.2 s, total: 12min 58s\n",
      "Wall time: 13min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cleaned_text = [regex_clean(s, removal_pattern=shipping_pattern) \n",
    "                for s in df.Text.values]\n",
    "# Wall time: 13min 2s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677fd934-3cbc-4e29-98e8-0951ed00bf17",
   "metadata": {},
   "source": [
    "# \"Embarassingly Simple\" for loop\n",
    "## If I'm just looping over each record in the dataset, why not split this amongst the different cores of my computer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6a41ad-47f1-4fc0-89ca-2de01132438b",
   "metadata": {},
   "source": [
    "## Designing joblib specification: number of jobs vs chunk size of each job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38024325-33a6-475d-b6b2-d2088e12d9fd",
   "metadata": {},
   "source": [
    "#### Job size: My machine has 4 cores. Chunk size: We'll test to see how memory-intensive this task is as we parallelize. How much data to give each core at a time?\n",
    "#### Testing will help us determine how many workers to parallelize at once, and what size chunks to give them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fdaaa2-bc91-49bf-a47b-2bc8ce871a31",
   "metadata": {},
   "source": [
    "## Create a function for joblib that takes an iterable input (workers/cores may be fed multiple chunks of data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e3a314-3d7d-4613-a082-7a954e0d41c0",
   "metadata": {},
   "source": [
    "#### Joblib returns an iterable of results, one from each worker (order-preserving)\n",
    "#### We may need to restructure our job to work on an iterable input, if we feed workers chunks of size > 1. If we were to instead feed each record as a separate job (iterating over a Dataframe/Series), we may spawn too many jobs and incur too much overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e8bae8a9-5e4f-4044-952d-b35b21aed4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_clean_parts(texts, removal_pattern):\n",
    "    \"\"\"\n",
    "    Wrapper for regex_clean() that takes as input \n",
    "    iterable of texts.\n",
    "    \n",
    "    # Arguments\n",
    "        texts: iterable of strings\n",
    "        removal_pattern: regex pattern string\n",
    "        \n",
    "    # Returns\n",
    "        iterable of strings of cleaned text\n",
    "    \"\"\"\n",
    "    return texts.apply(regex_clean, removal_pattern=removal_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e48bf26d-8a01-4842-9cf5-480c2145af49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk size: 142114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:  5.5min remaining:  5.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 752 ms, sys: 1.52 s, total: 2.27 s\n",
      "Wall time: 5min 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:  5.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:  5.6min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_jobs=4\n",
    "num_chunks=4\n",
    "chunk_size = math.ceil(df.shape[0] / num_chunks)\n",
    "print(\"Chunk size:\", chunk_size)\n",
    "\n",
    "cleaned_text = \\\n",
    "    Parallel(n_jobs=num_jobs, \n",
    "             # backend='loky', \n",
    "             prefer='processes', \n",
    "             batch_size='auto', \n",
    "             verbose=10)(delayed(regex_clean_parts)(t, removal_pattern=shipping_pattern) \n",
    "                         for t in [df.Text.iloc[i*chunk_size:(i+1)*chunk_size] \n",
    "                                   for i in range(num_chunks)])\n",
    "# jobs=chunks=4, Wall time: 6min 2s. \n",
    "# jobs=4, chunks=16, Wall time: 5min 58s\n",
    "# jobs=4, chunks=32, Wall time: 5min 46s\n",
    "# jobs=chunks=8, Wall time: 6min 4s\n",
    "# jobs=2, chunks=16, Wall time: 7min 18s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1309c6fa-c92d-4b83-8dc3-ee6e8de0fe98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1fb5123f-bd39-4c89-9aaa-191d9fa1396d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142114"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9e3d72dc-be4d-4948-8dc6-a444a993c1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918b7864-6797-487b-91bf-4e8f463c9102",
   "metadata": {},
   "source": [
    "#### Finally aggregate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e972ab8f-e31c-49c9-a296-9daab7cc7af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 115 ms, sys: 3.3 ms, total: 118 ms\n",
      "Wall time: 119 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cleaned_text = [t for l in cleaned_text for t in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a841783c-cb92-4773-b860-c47b324a60da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "568454"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_text)\n",
    "# 568454"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c77b15-d1a5-4e86-b836-f9325637d9da",
   "metadata": {},
   "source": [
    "#### Compared to 'each record' version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f407ccca-c135-448e-9201-4967731075a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.1881s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.0220s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=4)]: Done  28 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.0446s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=4)]: Done  56 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.0415s.) Setting batch_size=16.\n",
      "[Parallel(n_jobs=4)]: Done 116 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.0403s.) Setting batch_size=32.\n",
      "[Parallel(n_jobs=4)]: Done 292 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.0973s.) Setting batch_size=64.\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.1618s.) Setting batch_size=128.\n",
      "[Parallel(n_jobs=4)]: Done 772 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=4)]: Done 2180 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=4)]: Done 3844 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=4)]: Done 5764 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=4)]: Done 7684 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=4)]: Done 9860 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=4)]: Done 12036 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=4)]: Done 14468 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=4)]: Done 16900 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=4)]: Done 19588 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=4)]: Done 22276 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=4)]: Done 25220 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=4)]: Done 28164 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=4)]: Done 31364 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=4)]: Done 34564 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=4)]: Done 38020 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=4)]: Done 41476 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=4)]: Done 45188 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=4)]: Done 48900 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=4)]: Done 52868 tasks      | elapsed:   32.4s\n",
      "[Parallel(n_jobs=4)]: Done 56836 tasks      | elapsed:   34.8s\n",
      "[Parallel(n_jobs=4)]: Done 61060 tasks      | elapsed:   37.5s\n",
      "[Parallel(n_jobs=4)]: Done 65284 tasks      | elapsed:   40.2s\n",
      "[Parallel(n_jobs=4)]: Done 69764 tasks      | elapsed:   43.3s\n",
      "[Parallel(n_jobs=4)]: Done 74244 tasks      | elapsed:   46.4s\n",
      "[Parallel(n_jobs=4)]: Done 78980 tasks      | elapsed:   49.5s\n",
      "[Parallel(n_jobs=4)]: Done 83716 tasks      | elapsed:   52.5s\n",
      "[Parallel(n_jobs=4)]: Done 88708 tasks      | elapsed:   55.2s\n",
      "[Parallel(n_jobs=4)]: Done 93700 tasks      | elapsed:   59.0s\n",
      "[Parallel(n_jobs=4)]: Done 98948 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 104196 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 109700 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 115204 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 120964 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 126724 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 132740 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 138756 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 145028 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 151300 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 157828 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done 164356 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done 171140 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done 177924 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done 184964 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=4)]: Done 192004 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=4)]: Done 199300 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done 206596 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=4)]: Done 214148 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=4)]: Done 221700 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=4)]: Done 229508 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=4)]: Done 237316 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=4)]: Done 245380 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=4)]: Done 253444 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done 261764 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=4)]: Done 270084 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done 278660 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=4)]: Done 287236 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=4)]: Done 296068 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=4)]: Done 304900 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=4)]: Done 313988 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=4)]: Done 323076 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=4)]: Done 332420 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=4)]: Done 341764 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=4)]: Done 351364 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=4)]: Done 360964 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=4)]: Done 370820 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=4)]: Done 380676 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=4)]: Done 390788 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=4)]: Done 400900 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=4)]: Done 411268 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=4)]: Done 421636 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=4)]: Done 432260 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=4)]: Done 442884 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=4)]: Done 453764 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=4)]: Done 464644 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=4)]: Done 475780 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=4)]: Done 486916 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=4)]: Done 498308 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=4)]: Done 509700 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=4)]: Done 521348 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=4)]: Done 532996 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=4)]: Done 544900 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=4)]: Done 556804 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=4)]: Done 568089 tasks      | elapsed:  6.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.03 s, sys: 944 ms, total: 8.98 s\n",
      "Wall time: 6min 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 568454 out of 568454 | elapsed:  6.1min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_jobs=4\n",
    "\n",
    "cleaned_text = \\\n",
    "    Parallel(n_jobs=num_jobs, \n",
    "             # backend='loky', \n",
    "             prefer='processes', \n",
    "             batch_size='auto', \n",
    "             verbose=10)(delayed(regex_clean)(t, removal_pattern=shipping_pattern) \n",
    "                         for t in df.Text.values)\n",
    "# Wall time: 6min 4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c21dd9e-dfc2-4b4b-b236-fd180868b2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cbe60e-b1a8-4b62-b100-e5de422d32bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ab5d91-db36-46e1-b4a3-61fc7cf39c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4468aa0c-ba0b-43b3-a90d-d55bfb78c8b5",
   "metadata": {},
   "source": [
    "# Training anti-example - GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a19102-e2e1-45cd-bafe-ae61f7ef932b",
   "metadata": {},
   "source": [
    "#### GBM is inherently difficult to parallelize because each step is dependent upon the previous step in terms of how weights evolve and splits are chosen (ie, mining successive model residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8f0bf4-f4cc-4990-90b5-2af0238cfdf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c9f39be-0990-44e8-b606-1caf09ce6fe2",
   "metadata": {},
   "source": [
    "# Training example: hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b247ea-1ddd-4c2d-bea8-a41f83d8104e",
   "metadata": {},
   "source": [
    "## Classify review scores into high/low"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99360dc4-89cf-4535-afb6-d756ea008680",
   "metadata": {},
   "source": [
    "### Extract target: let Score=5 be \"1\" and Score < 5 be \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cd2baae8-37ac-4211-891a-d8a87b77cedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (df.Score == 5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e92edb4c-ed22-4a0d-8bfa-1f10fffec321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454,)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "100d48ae-4608-4085-b9f0-964d51f8497d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    363122\n",
       "0    205332\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca97ae7f-76e2-4a49-982e-f20ec57a48df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "17a8b1b9-f20d-42f8-8a1c-35d655191328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 124 ms, sys: 6.59 ms, total: 130 ms\n",
      "Wall time: 139 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "train_test_split(df.Text, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e2713158-0b26-4918-8570-5c5fbd8e3084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380864,)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0f998be6-535c-4371-ab6f-5c996f46fa97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187590,)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "57fb7b05-e85d-4477-9c08-290f9a9eab62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380864,)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c6905c1f-d823-4783-834c-1be45a30392f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187590,)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "307264ae-9340-4774-a4e2-d047d4a5d6f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I buy this exact same product at a large oriental market here in Florida...same size package for $1.49. I think they are fantastic for making sushi summer rolls. Make sure you are rolling them tight enough and don't soak them as long as the package says...as some of the product you add will add more moisture...I actually spritz mine instead of soaking and you can always spritz a little water on them later if need be. These performed for me just as they should.\""
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b16f6f4a-80f9-4b6a-a658-6fda53cce76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6bde23-ed9c-4684-9236-d74f9b5d29b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "180a318c-c341-4a8f-a874-66928f7f26ea",
   "metadata": {},
   "source": [
    "### Generate some features, using code from https://developers.google.com/machine-learning/guides/text-classification/step-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f98c1f-5012-48fe-b58c-5fd41940acaa",
   "metadata": {},
   "source": [
    "#### Top twenty words encoded as features, according to f_classif score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d99d14dd-5303-4b23-8137-01f9fc0b5b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# Vectorization parameters\n",
    "# Range (inclusive) of n-gram sizes for tokenizing text.\n",
    "NGRAM_RANGE = (1, 2)\n",
    "\n",
    "# Limit on the number of features. We use the top 20K features.\n",
    "TOP_K = 20\n",
    "\n",
    "# Whether text should be split into word or character n-grams.\n",
    "# One of 'word', 'char'.\n",
    "TOKEN_MODE = 'word'\n",
    "\n",
    "# Minimum document/corpus frequency below which a token will be discarded.\n",
    "MIN_DOCUMENT_FREQUENCY = 200\n",
    "\n",
    "def ngram_vectorize(train_texts, train_labels, val_texts):\n",
    "    \"\"\"Vectorizes texts as n-gram vectors.\n",
    "\n",
    "    1 text = 1 tf-idf vector the length of vocabulary of unigrams + bigrams.\n",
    "\n",
    "    # Arguments\n",
    "        train_texts: list, training text strings.\n",
    "        train_labels: np.ndarray, training labels.\n",
    "        val_texts: list, validation text strings.\n",
    "\n",
    "    # Returns\n",
    "        x_train, x_val: vectorized training and validation texts\n",
    "    \"\"\"\n",
    "    # Create keyword arguments to pass to the 'tf-idf' vectorizer.\n",
    "    kwargs = {\n",
    "            'ngram_range': NGRAM_RANGE,  # Use 1-grams + 2-grams.\n",
    "            'dtype': 'int32',\n",
    "            'strip_accents': 'unicode',\n",
    "            'decode_error': 'replace',\n",
    "            'analyzer': TOKEN_MODE,  # Split text into word tokens.\n",
    "            'min_df': MIN_DOCUMENT_FREQUENCY,\n",
    "    }\n",
    "    vectorizer = TfidfVectorizer(**kwargs)\n",
    "\n",
    "    # Learn vocabulary from training texts and vectorize training texts.\n",
    "    x_train = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "    # Vectorize validation texts.\n",
    "    x_val = vectorizer.transform(val_texts)\n",
    "\n",
    "    # Select top 'k' of the vectorized features.\n",
    "    selector = SelectKBest(f_classif, k=min(TOP_K, x_train.shape[1]))\n",
    "    selector.fit(x_train, train_labels)\n",
    "    x_train = selector.transform(x_train).astype('float32')\n",
    "    x_val = selector.transform(x_val).astype('float32')\n",
    "    return x_train, x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "53b21f38-d187-4aa1-a241-2425ea3a5195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ciel/miniconda3/envs/pydata22-joblib/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:2019: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 12s, sys: 10.5 s, total: 1min 23s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_val = ngram_vectorize(X_train, y_train, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1b712dca-eb01-4c65-b28f-08dd40f34a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380864, 20)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "51af6c69-7259-422c-bf20-25e728f30acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187590, 20)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfa5e55-c42f-4a84-a417-0abf379a67a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a189baac-4021-4ac0-be93-afd871059167",
   "metadata": {},
   "source": [
    "## Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b25d212e-cf05-472b-9cd1-e7b8409d1f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_grid = {'learning_rate': [0.01, 0.001],\n",
    "           'n_estimators': [100, 500, 1000],\n",
    "           'subsample': [1.0, 0.8, 0.5],\n",
    "           'max_depth': [2, 3, 4]\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59802778-29c9-46f0-aae0-a8b17dc5f582",
   "metadata": {},
   "source": [
    "### Generate iterable of hyper-parameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ba2a969a-2649-4243-8cca-35e3f99e5570",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_combos = []\n",
    "for k in hp_grid.keys():\n",
    "    hp_combos.append([(k, v) for v in hp_grid[k]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3b79e534-b620-4444-8d74-10ef681191a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_combos = list(itertools.product(*hp_combos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fb2a76-2cbb-487f-8fe4-21f5e7f7ee04",
   "metadata": {},
   "source": [
    "## Fit a single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "69f6f9fd-55a3-4067-94dd-60a810d31445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01, 'n_estimators': 100, 'subsample': 1.0, 'max_depth': 2}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(hp_combos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c4f424a5-9868-410b-84fa-84c798916062",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_gbm = GradientBoostingClassifier(**dict(hp_combos[0]), \n",
    "                                    min_samples_split=20, \n",
    "                                    min_samples_leaf=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "aa661a08-7598-4ea7-8332-22681e383249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 122 ms, total: 1min 4s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "my_gbm = my_gbm.fit(X_train, y_train)\n",
    "# Wall time: 1min 4s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b8ff24-f969-4254-bc99-04df5d0603a2",
   "metadata": {},
   "source": [
    "### Evaluate model on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "397d4ea4-18f3-43f0-92c4-88dad1f52afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 192 ms, sys: 22 µs, total: 192 ms\n",
      "Wall time: 191 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred_val = my_gbm.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "cc05ce95-13d0-4c46-9f21-340b069804eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56 ms, sys: 10 µs, total: 56 ms\n",
      "Wall time: 54 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "val_auc = roc_auc_score(y_val, pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "807063da-7162-4f0c-949e-4d1bd5de6613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5003981908781411"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351c1aa8-9273-4776-adb7-155b45c72702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51a78079-465d-432a-9ae4-0531b705e9e7",
   "metadata": {},
   "source": [
    "## Use joblib to fit and evaluate many models, one model per worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8930fc2b-0920-42c3-bf1b-b37c25c7de86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_eval(hp_combo, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Fit and evaluate a sklearn GBM classifier.\n",
    "    \n",
    "    # Arguments\n",
    "        hp_combo: Iterable of (hyper-parameter \n",
    "            string, value) tuples.\n",
    "        X_train: training data\n",
    "        y_train: training labels\n",
    "        X_val: holdout data\n",
    "        y_val: holdout labels\n",
    "        \n",
    "    # Return\n",
    "        Tuple of (dictionary of model parameters, \n",
    "        float for validation AUC score).\n",
    "    \"\"\"\n",
    "    my_gbm = GradientBoostingClassifier(**dict(hp_combo), \n",
    "                                        min_samples_split=20, \n",
    "                                        min_samples_leaf=20)\n",
    "    my_gbm = my_gbm.fit(X_train, y_train)\n",
    "    pred_val = my_gbm.predict(X_val)\n",
    "    val_auc = roc_auc_score(y_val, pred_val)\n",
    "    return (hp_combo, val_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "18758793-a0ba-4509-a884-9d93037e2da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hp_combos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44270673-485d-4da1-b9f4-0ea4bb39451d",
   "metadata": {},
   "source": [
    "### 54 combos - at 1 minute each that's about an hour if we iterated over them one at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3b9d6e-4990-411d-af2e-d8fb33dc3a31",
   "metadata": {},
   "source": [
    "#### Without joblib, looping through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "355ca3e9-1612-4bcb-8ac3-0d7dd38b6e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58min 44s, sys: 3.7 s, total: 58min 48s\n",
      "Wall time: 59min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hp_grid_results0 = []\n",
    "for hp_combo in hp_combos:\n",
    "    hp_grid_results_i = fit_and_eval(hp_combo, X_train, y_train, X_val, y_val)\n",
    "    hp_grid_results0.append(hp_grid_results_i)\n",
    "# Wall time: 59min 17s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e256cf8b-ceaa-4c41-95a9-14e928ee4cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hp_grid_results0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb39c11-45c1-4554-8129-8cc7841cdc5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53da3681-551a-4d5e-89ac-a123b00ed44e",
   "metadata": {},
   "source": [
    "### With joblib..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "1e85cad7-c306-468e-ba43-ae9a376557f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_eval_parts(hp_list, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Fit and evaluate a series of sklearn GBM classifier.\n",
    "    \n",
    "    # Arguments\n",
    "        hp_list: Iterable of iterable of \n",
    "            (hyper-parameter, value) tuples.\n",
    "        X_train: training data\n",
    "        y_train: training labels\n",
    "        X_val: holdout data\n",
    "        y_val: holdout labels\n",
    "        \n",
    "    # Return\n",
    "        List of (dictionary of model parameters, float for \n",
    "        validation AUC score).\n",
    "    \"\"\"\n",
    "    hp_grid_results = []\n",
    "    for hp_combo in hp_list:\n",
    "        hp_grid_results_i = fit_and_eval(hp_combo, X_train, y_train, X_val, y_val)\n",
    "        hp_grid_results.append(hp_grid_results_i)\n",
    "    return hp_grid_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b012aa63-11fb-4f1a-a1f2-ebff61b82d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed: 21.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 281 ms, sys: 514 ms, total: 794 ms\n",
      "Wall time: 26min 19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  54 out of  54 | elapsed: 26.3min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_jobs = 4\n",
    "\n",
    "hp_grid_results = \\\n",
    "    Parallel(n_jobs=num_jobs, \n",
    "             # backend='loky', \n",
    "             prefer='processes', \n",
    "             batch_size='auto', \n",
    "             verbose=10)(delayed(fit_and_eval)(hp_combo, \n",
    "                                               X_train=X_train, \n",
    "                                               y_train=y_train, \n",
    "                                               X_val=X_val, \n",
    "                                               y_val=y_val) \n",
    "                         for hp_combo in hp_combos)\n",
    "# 4 jobs, 54 tasks - Wall time: 26min 19s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "87e83712-2231-4a39-a526-276fa2206ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hp_grid_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "dd3b9acd-e659-4e1b-aa13-820e4d653c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((('learning_rate', 0.01),\n",
       "  ('n_estimators', 100),\n",
       "  ('subsample', 1.0),\n",
       "  ('max_depth', 3)),\n",
       " 0.5003981908781411)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_grid_results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "02d487c2-69c6-46a3-9353-2d82d7a5b907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk size: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed: 14.6min\n",
      "[Parallel(n_jobs=4)]: Done   9 out of  14 | elapsed: 21.9min remaining: 12.2min\n",
      "[Parallel(n_jobs=4)]: Done  11 out of  14 | elapsed: 22.0min remaining:  6.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 134 ms, sys: 282 ms, total: 416 ms\n",
      "Wall time: 26min 18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  14 out of  14 | elapsed: 26.3min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_jobs = 4\n",
    "num_chunks = 4\n",
    "chunk_size = math.ceil(len(hp_combos) / num_chunks)\n",
    "\n",
    "print(\"Chunk size:\", chunk_size)\n",
    "hp_grid_results = \\\n",
    "    Parallel(n_jobs=num_jobs, \n",
    "             # backend='loky', \n",
    "             prefer='processes', \n",
    "             batch_size='auto', \n",
    "             verbose=10)(delayed(fit_and_eval_parts\n",
    "                                )(hp, \n",
    "                                  X_train=X_train, \n",
    "                                  y_train=y_train, \n",
    "                                  X_val=X_val, \n",
    "                                  y_val=y_val) \n",
    "                         for hp in [\n",
    "                             hp_combos[i*chunk_size:(i+1)*chunk_size] \n",
    "                             for i in range(num_chunks)])\n",
    "# 4 jobs, 4 tasks - Wall time: 25min 3s\n",
    "# 4 jobs, 14 tasks - Wall time: 26min 18s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "348de8cc-4c0f-4814-aac1-7e962870dc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hp_grid_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb153d6-5fde-447d-ae0a-0774ad61711b",
   "metadata": {},
   "source": [
    "#### Aggregate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8a658e90-4985-4c75-9f4b-6f050ebd9e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26 µs, sys: 1 µs, total: 27 µs\n",
      "Wall time: 36.5 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hp_grid_results = [r for l in hp_grid_results for r in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "9f8c0b78-d610-4b0b-ab67-6be7c861870e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hp_grid_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56c68ed-5d63-4743-93e9-df3140b27178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3dfe8c4-eac6-4d77-adaf-48a7667a4b44",
   "metadata": {},
   "source": [
    "# A word on scoring. Use built-in functions if they're available to score in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886b0d2e-7800-4200-80ff-e29118555533",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
